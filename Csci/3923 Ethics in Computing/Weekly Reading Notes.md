### Week 2
**Reading**:
- [A Jargon-Free Explanation of How AI Large Language Models Work](https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/)
- [Would Luddites find the gig economy familiar?](https://arstechnica.com/gadgets/2024/01/would-luddites-find-the-gig-economy-familiar/)
- [Software Engineers Need a Crash Course in Ethics](https://slate.com/technology/2013/09/software-engineers-need-a-crash-course-in-ethics.html)
- [ACM Code of Ethics](https://www.acm.org/code-of-ethics)

**Writing**:
1. From the article "A jargon-free explanation of how AI large language models work", I learned that LLMs use word vectors to represent words and reason about their relationships using vector arithmetic. From "Would Luddites find the gig economy familiar?", I learned that Luddites were not against technology or progress but rather against the exploitation of workers. From "Software Engineers Need a Crash Course in Ethics", I learned that software engineers often just create programs without considering the ethical implications of their work. From the "ACM Code of Ethics and Professional Conduct", I learned that computing professionals should act in a way that benefits society and avoids harm.  
2. I would like to learn more about vector arithmetic in LLMs because I think it's interesting how it can capture relationships between words. One step I could take to learn more about it is to read articles that go into more detail about how LLMs use vector arithmetic and maybe try to implement some simple examples myself.  
3. I would teach my friend about the ethical responsibilities of software engineers because I think it's important for people in the tech industry to consider the impact of their work on society. Often, when I'm working on a project, or learning any new technology, I don't think about the ethical implications of what I'm doing and I think it's something that more people should be aware of.  
4. By knowing that AI models can produce biased content based on their training data, I can be more careful about trusting AI generated information and ensure that I verify it from reliable sources before sharing it with others.  
5. Knowing about the ethical responsibilities of software engineers can help me and others use AI to help solve meaningful problems, like using it to make education more accessible while also being aware of and mitigating any negative impacts it might have.

### Week 3
**Reading**:
- [A Framework for Ethical Decision Making](https://www.scu.edu/ethics/ethics-resources/a-framework-for-ethical-decision-making/)
- Why Machine Ethics? - no link pdf
- [Case Study: Dark UX Patterns](https://www.acm.org/code-of-ethics/case-studies/dark-ux-patterns)

**Writing**:
1. I learned the most from the "Framework for Ethical Decision Making" because it provided an in depth explanation of different ethical lenses and how to apply them for making ethical decisions.
2. A key point from the "Why Machine Ethics?" article is the contextual nature of ethics. This relates to the importance of ethics in general because there is no single ethical lens that can be applied to all situations. Instead, to make an ethical decision, you have to consider the specific context and circumstances of each situation, then apply the most appropriate ethical lens or combination of lenses to that situation.

### ### Week 4
**Reading**:
- [ChatGPT is one year old. Here’s how it changed the tech world.](https://arstechnica.com/information-technology/2023/11/chatgpt-was-the-spark-that-lit-the-fire-under-generative-ai-one-year-ago-today/)
- [Why it’s a mistake to ask chatbots about their mistakes](https://arstechnica.com/ai/2025/08/why-its-a-mistake-to-ask-chatbots-about-their-mistakes/)

**Writing**:
1. The two most important things I have learned about how generative AI works are word vectors and transformers. Word vectors allow LLMs to represent and reason about words using vector arithmetics, which is crucial for understanding relationships between words. Transformers are how LLMs process and generate text. LLMs use many layers of transformers to refine their understanding of the input text and generate coherent output. Each transformer has a two step process for updating what it knows about the input text, attention and feedforward. In the attention step, the model looks at all the words in the input text and decides which ones are most relevant to the current word it's processing. In the feedforward step, the model "thinks" about the current word and the relevant words it identified in the attention step, and updates its understanding of the input text accordingly.  
2. The two most important things I think the public should know about how generative AI works are that LLMs are not sentient beings and that they cannot meaningfully assess their own capabilities. It's important for the public to understand that LLMs are tools that generate text based on patterns in their training data, not self-aware entities. This understanding can help prevent people from attributing human-like qualities to these models and expecting them to behave like humans. Additionally, knowing that LLMs cannot accurately evaluate their own performance can help users be more critical of the information generated by these models and avoid being misled.

### Week 6
**Reading**:
- [US Copyright Office website](https://www.copyright.gov/)
- [I really don’t like ChatGPT’s new memory dossier](https://simonwillison.net/2025/May/21/chatgpt-new-memory/)

**Writing**:
1. I learned that James Madison introduced the idea of copyright to the US Congress in 1787 and that congress passed the first federal copyright law in 1790.  
2. I read the Simon Willison article. One important thing from the article is that ChatGPT's new memory feature allows it to remember past interactions. It does this by maintaining a detailed summary of the user's pervious conversations, this summary then gets included into the context of every new conversation. I think this is important to know because ChatGPT is essentially storing information about you without your consent.

### Week 6
**Reading**:
- [AI Ethics Guidelines that Organizations Should Consider](https://www.forbes.com/councils/forbestechcouncil/2023/06/15/ai-ethics-guidelines-that-organizations-should-consider/)
- [universal guidelines for ai](https://www.caidp.org/universal-guidelines-for-ai/)
- [Black Hat: Sloppy AI defenses take cybersecurity back to the 1990s, researchers say](https://www.scworld.com/news/sloppy-ai-defenses-take-cybersecurity-back-to-the-1990s-researchers-say)

**Writing**:
1. One important thing I learned from the AI Ethics Guidelines reading is the importance of transparency when it comes to AI systems. It is important for organizations to be open about how they are using AI and to ensure that they are not perpetuating biases or discrimination.
2. I was not surprised by any of the guidelines listed in the Universal Guidelines reading because they all seemed like common sense when it comes to the development of AI.  
3. One important thing I learned about AI and security is that that many AI developers are repeating the same mistakes that were made in the early days of the internet when it comes to security. I also learned that prompt injections are a major security risk for AI systems and that they can be used to manipulate the output of an AI system.
